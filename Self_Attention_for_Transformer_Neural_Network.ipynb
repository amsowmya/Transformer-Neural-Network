{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 1.23767444  0.18502693 -1.09854368  0.16503678  0.31023597 -0.37130178\n",
      "   0.6124875   0.25187821]\n",
      " [-1.37761389 -0.7662307  -1.4039775   1.49568658  0.74314376 -2.19738003\n",
      "   0.71133727  2.01005643]\n",
      " [ 1.20876575 -0.27331337 -0.65803996  0.80016005  0.66394185 -2.26971528\n",
      "  -0.49590017  0.02441049]\n",
      " [-1.51969392  0.43542701  0.23870059  0.23507748 -0.63689157  0.89787709\n",
      "  -0.04342489  0.97911984]]\n",
      "K\n",
      " [[ 0.08344936  1.30839146 -0.1798441  -0.0232427  -0.10818522  0.8712742\n",
      "  -0.74525497  0.22306002]\n",
      " [-0.35561789 -0.29492574 -0.04721697 -0.46935789 -0.3424444   0.33506727\n",
      "   0.16858585  0.62867649]\n",
      " [-0.43523471 -0.35258237 -0.41215324 -0.234798    0.34846414 -1.61257461\n",
      "  -0.7165962  -0.44720911]\n",
      " [-0.4904113   0.73225942 -0.21706811  0.88411808 -0.65757577  0.95325741\n",
      "  -0.20484205  0.0970765 ]]\n",
      "V\n",
      " [[ 3.85965083e-02 -3.25931476e-01  4.19487217e-01  5.29292944e-01\n",
      "  -5.92452147e-01 -2.96825284e-01 -2.23785032e-01  8.50729990e-01]\n",
      " [-1.83609861e-01  7.60972745e-01 -6.70625975e-01  1.14855517e+00\n",
      "   1.79830844e+00 -1.42103673e-01  1.93557416e+00  5.76014368e-01]\n",
      " [-3.76030492e-01 -5.98083204e-01 -1.23195150e+00  4.85214972e-01\n",
      "  -1.00111085e+00  6.37273937e-01 -4.57567819e-01  9.20028195e-01]\n",
      " [ 2.05373222e+00  6.17287037e-01 -1.63883759e+00 -1.56868984e-04\n",
      "   2.56137375e-01 -2.72584720e-01 -3.86595733e-01  5.40588637e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2182425 , -0.4893428 , -0.03458858, -0.74607259],\n",
       "       [-2.9764395 ,  0.47300563,  3.49095555, -0.79228462],\n",
       "       [-1.83133939, -1.74986828,  3.88949474, -2.4389173 ],\n",
       "       [ 1.49646326,  1.4175835 , -1.72225815,  2.59879978]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0413895219605402, 0.3467872290805614, 4.0121944848665745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0413895219605402, 0.3467872290805614, 0.5015243106083216)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07716037, -0.17300881, -0.01222891, -0.26377649],\n",
       "       [-1.05233028,  0.16723275,  1.23423917, -0.28011491],\n",
       "       [-0.64747625, -0.61867186,  1.37514405, -0.86228748],\n",
       "       [ 0.52907966,  0.50119145, -0.60891021,  0.91881447]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "\n",
    "- This is to ensure words don't get context from words generated in the future.\n",
    "- Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((L, L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07716037,        -inf,        -inf,        -inf],\n",
       "       [-1.05233028,  0.16723275,        -inf,        -inf],\n",
       "       [-0.64747625, -0.61867186,  1.37514405,        -inf],\n",
       "       [ 0.52907966,  0.50119145, -0.60891021,  0.91881447]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = softmax(scaled + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.22801336, 0.77198664, 0.        , 0.        ],\n",
       "       [0.10430436, 0.10735247, 0.78834316, 0.        ],\n",
       "       [0.26528374, 0.25798766, 0.0850135 , 0.3917151 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03859651, -0.32593148,  0.41948722,  0.52929294, -0.59245215,\n",
       "        -0.29682528, -0.22378503,  0.85072999],\n",
       "       [-0.13294384,  0.51314406, -0.4220656 ,  1.00735511,  1.25318309,\n",
       "        -0.17738227,  1.44321142,  0.6386532 ],\n",
       "       [-0.31212626, -0.42379857, -0.99943955,  0.56102371, -0.65796138,\n",
       "         0.4561752 , -0.17627354,  0.87586935],\n",
       "       [ 0.73538019,  0.30081276, -0.80842003,  0.47791425,  0.3219984 ,\n",
       "        -0.16800258,  0.24965289,  0.66426098]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.85965083e-02, -3.25931476e-01,  4.19487217e-01,\n",
       "         5.29292944e-01, -5.92452147e-01, -2.96825284e-01,\n",
       "        -2.23785032e-01,  8.50729990e-01],\n",
       "       [-1.83609861e-01,  7.60972745e-01, -6.70625975e-01,\n",
       "         1.14855517e+00,  1.79830844e+00, -1.42103673e-01,\n",
       "         1.93557416e+00,  5.76014368e-01],\n",
       "       [-3.76030492e-01, -5.98083204e-01, -1.23195150e+00,\n",
       "         4.85214972e-01, -1.00111085e+00,  6.37273937e-01,\n",
       "        -4.57567819e-01,  9.20028195e-01],\n",
       "       [ 2.05373222e+00,  6.17287037e-01, -1.63883759e+00,\n",
       "        -1.56868984e-04,  2.56137375e-01, -2.72584720e-01,\n",
       "        -3.86595733e-01,  5.40588637e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention = softmax(scaled)\n",
    "    out = np.matmul(attention, v)\n",
    "    return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 1.23767444  0.18502693 -1.09854368  0.16503678  0.31023597 -0.37130178\n",
      "   0.6124875   0.25187821]\n",
      " [-1.37761389 -0.7662307  -1.4039775   1.49568658  0.74314376 -2.19738003\n",
      "   0.71133727  2.01005643]\n",
      " [ 1.20876575 -0.27331337 -0.65803996  0.80016005  0.66394185 -2.26971528\n",
      "  -0.49590017  0.02441049]\n",
      " [-1.51969392  0.43542701  0.23870059  0.23507748 -0.63689157  0.89787709\n",
      "  -0.04342489  0.97911984]]\n",
      "K\n",
      " [[ 0.08344936  1.30839146 -0.1798441  -0.0232427  -0.10818522  0.8712742\n",
      "  -0.74525497  0.22306002]\n",
      " [-0.35561789 -0.29492574 -0.04721697 -0.46935789 -0.3424444   0.33506727\n",
      "   0.16858585  0.62867649]\n",
      " [-0.43523471 -0.35258237 -0.41215324 -0.234798    0.34846414 -1.61257461\n",
      "  -0.7165962  -0.44720911]\n",
      " [-0.4904113   0.73225942 -0.21706811  0.88411808 -0.65757577  0.95325741\n",
      "  -0.20484205  0.0970765 ]]\n",
      "V\n",
      " [[ 3.85965083e-02 -3.25931476e-01  4.19487217e-01  5.29292944e-01\n",
      "  -5.92452147e-01 -2.96825284e-01 -2.23785032e-01  8.50729990e-01]\n",
      " [-1.83609861e-01  7.60972745e-01 -6.70625975e-01  1.14855517e+00\n",
      "   1.79830844e+00 -1.42103673e-01  1.93557416e+00  5.76014368e-01]\n",
      " [-3.76030492e-01 -5.98083204e-01 -1.23195150e+00  4.85214972e-01\n",
      "  -1.00111085e+00  6.37273937e-01 -4.57567819e-01  9.20028195e-01]\n",
      " [ 2.05373222e+00  6.17287037e-01 -1.63883759e+00 -1.56868984e-04\n",
      "   2.56137375e-01 -2.72584720e-01 -3.86595733e-01  5.40588637e-01]]\n",
      "New V\n",
      " [[ 0.30866806  0.06293211 -0.7526806   0.54934584  0.04881311  0.0073328\n",
      "   0.19073548  0.73694488]\n",
      " [ 0.00987135 -0.14026611 -1.06898812  0.56082418 -0.23192262  0.29915212\n",
      "   0.06038027  0.79463629]\n",
      " [-0.12850884 -0.34299854 -1.04906408  0.51746974 -0.58701697  0.39961518\n",
      "  -0.19259693  0.84984777]\n",
      " [ 0.73538019  0.30081276 -0.80842003  0.47791425  0.3219984  -0.16800258\n",
      "   0.24965289  0.66426098]]\n",
      "Attention\n",
      " [[0.26278102 0.23876329 0.28040992 0.21804576]\n",
      " [0.06100766 0.20655413 0.60038369 0.13205452]\n",
      " [0.09620916 0.09902071 0.72715881 0.07761133]\n",
      " [0.26528374 0.25798766 0.0850135  0.3917151 ]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=None)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 1.23767444  0.18502693 -1.09854368  0.16503678  0.31023597 -0.37130178\n",
      "   0.6124875   0.25187821]\n",
      " [-1.37761389 -0.7662307  -1.4039775   1.49568658  0.74314376 -2.19738003\n",
      "   0.71133727  2.01005643]\n",
      " [ 1.20876575 -0.27331337 -0.65803996  0.80016005  0.66394185 -2.26971528\n",
      "  -0.49590017  0.02441049]\n",
      " [-1.51969392  0.43542701  0.23870059  0.23507748 -0.63689157  0.89787709\n",
      "  -0.04342489  0.97911984]]\n",
      "K\n",
      " [[ 0.08344936  1.30839146 -0.1798441  -0.0232427  -0.10818522  0.8712742\n",
      "  -0.74525497  0.22306002]\n",
      " [-0.35561789 -0.29492574 -0.04721697 -0.46935789 -0.3424444   0.33506727\n",
      "   0.16858585  0.62867649]\n",
      " [-0.43523471 -0.35258237 -0.41215324 -0.234798    0.34846414 -1.61257461\n",
      "  -0.7165962  -0.44720911]\n",
      " [-0.4904113   0.73225942 -0.21706811  0.88411808 -0.65757577  0.95325741\n",
      "  -0.20484205  0.0970765 ]]\n",
      "V\n",
      " [[ 3.85965083e-02 -3.25931476e-01  4.19487217e-01  5.29292944e-01\n",
      "  -5.92452147e-01 -2.96825284e-01 -2.23785032e-01  8.50729990e-01]\n",
      " [-1.83609861e-01  7.60972745e-01 -6.70625975e-01  1.14855517e+00\n",
      "   1.79830844e+00 -1.42103673e-01  1.93557416e+00  5.76014368e-01]\n",
      " [-3.76030492e-01 -5.98083204e-01 -1.23195150e+00  4.85214972e-01\n",
      "  -1.00111085e+00  6.37273937e-01 -4.57567819e-01  9.20028195e-01]\n",
      " [ 2.05373222e+00  6.17287037e-01 -1.63883759e+00 -1.56868984e-04\n",
      "   2.56137375e-01 -2.72584720e-01 -3.86595733e-01  5.40588637e-01]]\n",
      "New V\n",
      " [[ 0.03859651 -0.32593148  0.41948722  0.52929294 -0.59245215 -0.29682528\n",
      "  -0.22378503  0.85072999]\n",
      " [-0.13294384  0.51314406 -0.4220656   1.00735511  1.25318309 -0.17738227\n",
      "   1.44321142  0.6386532 ]\n",
      " [-0.31212626 -0.42379857 -0.99943955  0.56102371 -0.65796138  0.4561752\n",
      "  -0.17627354  0.87586935]\n",
      " [ 0.73538019  0.30081276 -0.80842003  0.47791425  0.3219984  -0.16800258\n",
      "   0.24965289  0.66426098]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.22801336 0.77198664 0.         0.        ]\n",
      " [0.10430436 0.10735247 0.78834316 0.        ]\n",
      " [0.26528374 0.25798766 0.0850135  0.3917151 ]]\n"
     ]
    }
   ],
   "source": [
    "# For decoder pass mask\n",
    "\n",
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
