{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.27425579  3.30726302  1.21639574 -1.30345721  0.58099169 -0.10331169\n",
      "   1.20447982  1.82315813]\n",
      " [-1.14932628 -0.08398634  1.95051774 -0.11457736 -1.64998464 -0.20648265\n",
      "   0.28634909 -0.1754566 ]\n",
      " [-0.35376869  0.0277062   0.7418196   0.58293707 -0.4950439   0.51551094\n",
      "   0.83226284  0.37152595]\n",
      " [ 0.95910223  1.04487724 -1.206584    0.71541962  0.85301133  1.16689068\n",
      "   0.84551017  2.17667541]]\n",
      "K\n",
      " [[-0.48211478 -0.38406614 -0.17979803  0.78520215 -0.96527334 -0.6630798\n",
      "   0.62012532 -2.20334705]\n",
      " [-0.78279528  1.06238304  0.08317115 -0.8090412  -0.20314522 -0.1864577\n",
      "   0.55461076 -1.45649221]\n",
      " [ 0.65025037  0.79775616  0.02508248 -1.56677952 -1.0167757  -0.10593784\n",
      "   0.06236182 -0.27459765]\n",
      " [-0.69599466  1.03763871  0.40960599  1.97186402  0.45891292  1.17874799\n",
      "  -1.13045595 -0.83790218]]\n",
      "V\n",
      " [[ 2.41934434 -2.94570438 -0.15651827  0.92741815  0.53501952  0.07621312\n",
      "  -1.25600643  0.59494809]\n",
      " [-1.53663081 -0.70187285 -0.26943615 -0.96015249  0.85452404  0.023894\n",
      "   0.07307707  1.03708182]\n",
      " [ 0.29312605  0.01215789  2.33046738  0.29564742  0.82428626 -1.8225176\n",
      "  -0.21866879  0.65778061]\n",
      " [-1.8908105   0.66685244 -0.39763628 -1.41393801 -1.6823543  -0.58063555\n",
      "   0.37267215 -0.23033578]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.40704703,  2.36845307,  3.88414966, -1.57552724],\n",
       "       [ 2.43946264,  1.85343637,  1.17966667,  0.1085104 ],\n",
       "       [ 0.31779627, -0.17865697, -0.70404484,  0.85663308],\n",
       "       [-5.95378869, -3.41212043, -1.22987658,  0.3204361 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0788823578891231, 0.806879409904545, 7.6709803912297705)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0788823578891231, 0.806879409904545, 0.9588725489037212)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2652332 ,  0.83737461,  1.37325428, -0.557033  ],\n",
       "       [ 0.86248029,  0.65528871,  0.41707515,  0.03836422],\n",
       "       [ 0.11235795, -0.06316478, -0.24891744,  0.30286553],\n",
       "       [-2.10498218, -1.20636675, -0.43482703,  0.11329127]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "\n",
    "- This is to ensure words don't get context from words generated in the future.\n",
    "- Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((L, L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2652332 ,        -inf,        -inf,        -inf],\n",
       "       [ 0.86248029,  0.65528871,        -inf,        -inf],\n",
       "       [ 0.11235795, -0.06316478, -0.24891744,        -inf],\n",
       "       [-2.10498218, -1.20636675, -0.43482703,  0.11329127]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = softmax(scaled + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.55161339, 0.44838661, 0.        , 0.        ],\n",
       "       [0.39435203, 0.33086858, 0.2747794 , 0.        ],\n",
       "       [0.0556773 , 0.13675459, 0.29581307, 0.51175503]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.41934434, -2.94570438, -0.15651827,  0.92741815,  0.53501952,\n",
       "         0.07621312, -1.25600643,  0.59494809],\n",
       "       [ 0.64553804, -1.93960035, -0.20714914,  0.08105674,  0.67828107,\n",
       "         0.05275392, -0.66006318,  0.79319493],\n",
       "       [ 0.52619549, -1.39053142,  0.48949317,  0.12928276,  0.72021807,\n",
       "        -0.46282972, -0.53121545,  0.75850133],\n",
       "       [-0.95636001,  0.08486834,  0.4403292 , -0.71580263, -0.47047009,\n",
       "        -0.82875674,  0.06609433,  0.25165542]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.41934434, -2.94570438, -0.15651827,  0.92741815,  0.53501952,\n",
       "         0.07621312, -1.25600643,  0.59494809],\n",
       "       [-1.53663081, -0.70187285, -0.26943615, -0.96015249,  0.85452404,\n",
       "         0.023894  ,  0.07307707,  1.03708182],\n",
       "       [ 0.29312605,  0.01215789,  2.33046738,  0.29564742,  0.82428626,\n",
       "        -1.8225176 , -0.21866879,  0.65778061],\n",
       "       [-1.8908105 ,  0.66685244, -0.39763628, -1.41393801, -1.6823543 ,\n",
       "        -0.58063555,  0.37267215, -0.23033578]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention = softmax(scaled)\n",
    "    out = np.matmul(attention, v)\n",
    "    return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.27425579  3.30726302  1.21639574 -1.30345721  0.58099169 -0.10331169\n",
      "   1.20447982  1.82315813]\n",
      " [-1.14932628 -0.08398634  1.95051774 -0.11457736 -1.64998464 -0.20648265\n",
      "   0.28634909 -0.1754566 ]\n",
      " [-0.35376869  0.0277062   0.7418196   0.58293707 -0.4950439   0.51551094\n",
      "   0.83226284  0.37152595]\n",
      " [ 0.95910223  1.04487724 -1.206584    0.71541962  0.85301133  1.16689068\n",
      "   0.84551017  2.17667541]]\n",
      "K\n",
      " [[-0.48211478 -0.38406614 -0.17979803  0.78520215 -0.96527334 -0.6630798\n",
      "   0.62012532 -2.20334705]\n",
      " [-0.78279528  1.06238304  0.08317115 -0.8090412  -0.20314522 -0.1864577\n",
      "   0.55461076 -1.45649221]\n",
      " [ 0.65025037  0.79775616  0.02508248 -1.56677952 -1.0167757  -0.10593784\n",
      "   0.06236182 -0.27459765]\n",
      " [-0.69599466  1.03763871  0.40960599  1.97186402  0.45891292  1.17874799\n",
      "  -1.13045595 -0.83790218]]\n",
      "V\n",
      " [[ 2.41934434 -2.94570438 -0.15651827  0.92741815  0.53501952  0.07621312\n",
      "  -1.25600643  0.59494809]\n",
      " [-1.53663081 -0.70187285 -0.26943615 -0.96015249  0.85452404  0.023894\n",
      "   0.07307707  1.03708182]\n",
      " [ 0.29312605  0.01215789  2.33046738  0.29564742  0.82428626 -1.8225176\n",
      "  -0.21866879  0.65778061]\n",
      " [-1.8908105   0.66685244 -0.39763628 -1.41393801 -1.6823543  -0.58063555\n",
      "   0.37267215 -0.23033578]]\n",
      "New V\n",
      " [[-0.46500132 -0.2158945   1.20178039 -0.25446305  0.62295927 -1.07641854\n",
      "  -0.08815749  0.7098293 ]\n",
      " [ 0.18280683 -1.11199522  0.32602111 -0.09815142  0.35259455 -0.45866568\n",
      "  -0.40566842  0.60796817]\n",
      " [-0.25450549 -0.72598958  0.2029474  -0.36918269 -0.05582081 -0.5008814\n",
      "  -0.23925675  0.43910365]\n",
      " [-0.95636001  0.08486834  0.4403292  -0.71580263 -0.47047009 -0.82875674\n",
      "   0.06609433  0.25165542]]\n",
      "Attention\n",
      " [[0.014968   0.3331265  0.56929683 0.08260867]\n",
      " [0.34577535 0.2810683  0.22149149 0.15166486]\n",
      " [0.26697501 0.22399693 0.18602474 0.32300333]\n",
      " [0.0556773  0.13675459 0.29581307 0.51175503]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=None)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.27425579  3.30726302  1.21639574 -1.30345721  0.58099169 -0.10331169\n",
      "   1.20447982  1.82315813]\n",
      " [-1.14932628 -0.08398634  1.95051774 -0.11457736 -1.64998464 -0.20648265\n",
      "   0.28634909 -0.1754566 ]\n",
      " [-0.35376869  0.0277062   0.7418196   0.58293707 -0.4950439   0.51551094\n",
      "   0.83226284  0.37152595]\n",
      " [ 0.95910223  1.04487724 -1.206584    0.71541962  0.85301133  1.16689068\n",
      "   0.84551017  2.17667541]]\n",
      "K\n",
      " [[-0.48211478 -0.38406614 -0.17979803  0.78520215 -0.96527334 -0.6630798\n",
      "   0.62012532 -2.20334705]\n",
      " [-0.78279528  1.06238304  0.08317115 -0.8090412  -0.20314522 -0.1864577\n",
      "   0.55461076 -1.45649221]\n",
      " [ 0.65025037  0.79775616  0.02508248 -1.56677952 -1.0167757  -0.10593784\n",
      "   0.06236182 -0.27459765]\n",
      " [-0.69599466  1.03763871  0.40960599  1.97186402  0.45891292  1.17874799\n",
      "  -1.13045595 -0.83790218]]\n",
      "V\n",
      " [[ 2.41934434 -2.94570438 -0.15651827  0.92741815  0.53501952  0.07621312\n",
      "  -1.25600643  0.59494809]\n",
      " [-1.53663081 -0.70187285 -0.26943615 -0.96015249  0.85452404  0.023894\n",
      "   0.07307707  1.03708182]\n",
      " [ 0.29312605  0.01215789  2.33046738  0.29564742  0.82428626 -1.8225176\n",
      "  -0.21866879  0.65778061]\n",
      " [-1.8908105   0.66685244 -0.39763628 -1.41393801 -1.6823543  -0.58063555\n",
      "   0.37267215 -0.23033578]]\n",
      "New V\n",
      " [[ 2.41934434 -2.94570438 -0.15651827  0.92741815  0.53501952  0.07621312\n",
      "  -1.25600643  0.59494809]\n",
      " [ 0.64553804 -1.93960035 -0.20714914  0.08105674  0.67828107  0.05275392\n",
      "  -0.66006318  0.79319493]\n",
      " [ 0.52619549 -1.39053142  0.48949317  0.12928276  0.72021807 -0.46282972\n",
      "  -0.53121545  0.75850133]\n",
      " [-0.95636001  0.08486834  0.4403292  -0.71580263 -0.47047009 -0.82875674\n",
      "   0.06609433  0.25165542]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.55161339 0.44838661 0.         0.        ]\n",
      " [0.39435203 0.33086858 0.2747794  0.        ]\n",
      " [0.0556773  0.13675459 0.29581307 0.51175503]]\n"
     ]
    }
   ],
   "source": [
    "# For decoder pass mask\n",
    "\n",
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
